#ifndef __OPTIM_H__
#define __OPTIM_H__

/**
  \file
  Методы локальной оптимизации.
  
*/

/**
  \example xmin.c
*/

/**
  \example xneldermead.c
*/

/**
  \example xlevenbergmarquardt.c
*/

/**
  \example xhookejeeves.c
*/

/**
  Минимизация функции одного переменного.

  Используется комбинированный метод золотого сечения
  и квадратичной интерполяции.

  - Вход:
	- \f$fun\f$ - указатель на функцию
	- \f$a\f$ - левый конец исходного интервала
	- \f$b\f$ - правый конец исходного интервала
	- \f$abstol\f$ - желаемая длина интервала неопределенности конечного результата

  - Выход:
	- Функция возвращает найденное решение.

  Если \f$f\f$ имеет непрерывную вторую производную, положительную в точке
  минимума (не совпадающей ни с \f$a\f$, ни с \f$b\f$), то сходимость
  сверхлинейная порядка приблизительно \f$1.324\dots\f$
  В любом случае сходимость не может быть хуже, чем для метода золотого сечения.

  Функция является переводом фортрановской программы fmin из книги [FMM].
*/

double optim_min(double (*fun)(double), double a, double b, double abstol); 

/**
  Симплекс-метод Нелдера-Мида (``другой'' симплекс-метод).

  Функция находит локальный минимум функции \f$f(x)\f$, зависящей от \f$n\f$
  переменных, \f$n\ge 2\f$. Для минимизации используется симплекс-метод Нелдера-Мида
  (``другой'' симплекс-метод или метод деформируемого многогранника).
  Итерации метода продолжаются до тех пор, пока значения функции в вершинах
  текущего симплекса не будут отличаться более, чем на \f$ftol\f$, 
  и диаметр симплекса (в чебышевой норме) не будет превышать \f$xtol\f$.
  Алгоритм также останавливается при превышении максимально допустимого
  числа \f$maxfunevals\f$ вычислений значений функции или максимально допустимого 
  числа \f$maxiter\f$ итераций (построенных симплексов).

  - Вход:
    - \f$fun\f$ - указатель на функцию, вычисляющую \f$f(x)\f$
    - \f$n\f$ - число переменных функции \f$f(x)\f$
    - \f$initsimplex\f$ - флаг, показывающий, передается ли функции одно начальное приближение
        \f$x0\f$ (при \f$initsimplex = 0\f$) или целый симплекс \f$x\f$
        (при \f$initsimplex = 1\f$)     
    - \f$x0\f$ - массив длины \f$n\f$, при \f$initsimplex = 0\f$ содержащий 
        координаты начального приближения 
    - \f$x\f$ - \f$(n+1)\times n\f$-массив, при \f$initsimplex = 0\f$ содержащий 
        координаты вершин исходного симплекса 
    - \f$f\f$ - массив длины \f$n+1\f$
    - \f$ftol\f$ - допуск по значению функции
    - \f$xtol\f$ - допуск по \f$x\f$
    - \f$maxfunevals\f$ - максимальное число вычислений значений функции
    - \f$maxiter\f$ - максимальное число итераций
  - Выход:
    - \f$x0\f$ - найденная точка локального минимума
    - \f$f0\f$ - значение функции в этой точке
    - \f$x\f$ - координаты вершин последнего найденного симплекса
    - \f$f\f$ - значения функции \f$f(x)\f$ в вершинах последнего симплекса
    - \f$nfunevals\f$ - количество вычислений значений функции
    - \f$niter\f$ - число выполненных итераций
  - Функция возвращает
      - \f$1\f$, если значения функции в вершинах
        текущего симплекса отличаются не более, чем на \f$ftol\f$, 
        и диаметр симплекса (в чебышевой норме) не превышает \f$xtol\f$.
      - \f$-1\f$, если количество вычислений значений функции превысило \f$maxfun\f$
        или число итераций достигло \f$maxiter\f$

  - Рабочий массив:
    - \f$work\f$ - массив длины \f$4n\f$
*/
extern 
int optim_nelder_mead(
  double (*fun)(double*),
  size_t n,  
  int initsimplex,
  double *x0,
  double *f0,
  double *x,
  double *f,
  double ftol, double xtol,
  int maxfunevals, int maxiter,
  int *nfunevals, int *niter,
  double *work);

/**
  Метод Хука-Дживса.

  Функция находит локальный минимум функции \f$f(x)\f$, зависящей от \f$n\f$
  переменных, \f$n\ge 2\f$. Для минимизации используется метод Хука-Дживса.

  - Вход:
    - \f$fun\f$ - указатель на функцию, вычисляющую \f$f(x)\f$
    - \f$n\f$ - число переменных функции \f$f(x)\f$
    - \f$x\f$ - массив длины \f$n\f$, содержащий 
        координаты точки, с которой алгоритм начинает поиск 
    - \f$alpha\f$ - параметр, контролирующий изменение длины шага от
        итерации к итерации, \f$0 < alpha < 1\f$
    - \f$ftol\f$ - допуск по значению функции
    - \f$xtol\f$ - допуск по \f$x\f$
    - \f$maxfunevals\f$ - максимальное число вычислений значений функции
    - \f$maxiter\f$ - максимальное число итераций
  - Выход:
    - \f$x\f$ - найденная точка локального минимума
    - \f$f\f$ - значение функции в этой точке
    - \f$nfunevals\f$ - количество вычислений значений функции
    - \f$niter\f$ - число выполненных итераций
  - Функция возвращает
      - \f$1\f$ при успешном окончании.
      - \f$-1\f$, если количество вычислений значений функции превысило \f$maxfun\f$
        или число итераций достигло \f$maxiter\f$
  - Рабочий массив:
    - \f$work\f$ - массив длины \f$2n\f$
*/
extern
int optim_hooke_jeeves(
   double (*fun)(double*), 
   size_t n, 
   double* x,
   double alpha,  /* 0 < alpha < 1 может сильно повлиять на сходимость */
   double ftol, double xtol, 
   int maxfunevals, int maxiter, 
   double *f, 
   int *nfunevals, int *niter, 
   double *work);  

/**
  Метод Левенберга-Марквардта.

  Функция находит локальный минимум функции \f$f(x)=\sum_{i=1}^m f_i(x)^n\f$, 
  где \f$x=(x_1,x_2,\dots,x_n)^{\rm T}\f$. Используется метод Левенберга-Марквардта.

  - Вход:
    - \f$fun\f$ - указатель на функцию, вычисляющую вектор
      значений \f$(f_1(x), f_2(x),\dots,f_m(x))\f$
    - \f$jac\f$ - указатель на функцию, вычисляющую матрицу Якоби
    - \f$n\f$ - число переменных
    - \f$m\f$ - количество слагаемых в сумме \f$\sum_{i=1}^m f_i(x)^n\f$
    - \f$x\f$ - массив длины \f$n\f$, содержащий 
        координаты точки, с которой алгоритм начинает поиск 
    - \f$ftol\f$ - допуск по значению функции
    - \f$xtol\f$ - допуск по \f$x\f$
    - \f$maxfunevals\f$ - максимальное число вычислений значений функции
    - \f$maxiter\f$ - максимальное число итераций
  - Выход:
    - \f$x\f$ - найденная точка локального минимума
    - \f$f0\f$ - значение функции в этой точке
    - \f$f\f$ - вектор длины \f$m\f$, содержащий значения функций
      \f$(f_1(x), f_2(x),\dots,f_m(x))\f$ в найденных точках
    - \f$niter\f$ - число выполненных итераций
    - \f$nfunevals\f$ - число обращений к функции \f$fun\f$
    - \f$njacevals\f$ - число обращений к функции \f$jac\f$
    - \f$J\f$ - матрицы Якоби в оптимальной точке
    - \f$g\f$ - градиент функции в оптимальной точке
    - \f$H\f$ - приближенное значение матрицы Гессе в оптимальной точке
  - Функция возвращает
      - \f$1\f$ при успешном окончании.
      - \f$-1\f$, если количество вычислений значений функции превысило \f$maxfun\f$
        или число итераций достигло \f$maxiter\f$
  - Рабочий массив:
    - \f$work\f$ - массив длины \f$2n+m\f$
*/
extern
int optim_levenberg_marquardt(
   void (*fun)(double*, double*), 
   void (*jac)(double*, double*), 
   size_t n, 
   size_t m, 
   double* x, 
   double ftol, 
   double xtol, 
   int maxfunevals, 
   int maxiter, 
   double *f0, 
   double *f, 
   int *niter, 
   int *nfunevals, 
   int *njacevals, 
   double *J, 
   double *g, 
   double *H, 
   double *work);  

#endif
